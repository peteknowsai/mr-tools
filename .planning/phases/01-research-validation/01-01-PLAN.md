---
phase: 01-research-validation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - .planning/research/video-generation-findings.md
  - tools/nanobanana/video_research.py
autonomous: false

must_haves:
  truths:
    - "Video generation request format is captured from browser DevTools"
    - "Polling mechanism for video status is identified (or confirmed absent)"
    - "Video retrieval endpoint and auth requirements are documented"
    - "A video file exists on Desktop (proof of concept) OR blockers are documented"
  artifacts:
    - path: ".planning/research/video-generation-findings.md"
      provides: "Complete documentation of video generation lifecycle"
      contains: "## Endpoints"
    - path: "tools/nanobanana/video_research.py"
      provides: "Working proof-of-concept script (if feasible)"
      min_lines: 50
  key_links:
    - from: "video_research.py"
      to: "~/.nanobanana/cookies.json"
      via: "cookie auth loading"
      pattern: "load_cookies|COOKIE_FILE"
    - from: "video_research.py"
      to: "gemini.google.com"
      via: "HTTP requests to discovered endpoints"
      pattern: "httpx|POST|GET"
---

<objective>
Validate cookie-based video generation via the Gemini web interface

Purpose: Determine if free video generation (via AI Pro subscription cookies) is feasible before investing in implementation. This is a go/no-go gate for the entire video feature.

Output: Either a video file on Desktop (success path) OR documented blockers explaining why it's not feasible (drop the feature).
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-research-validation/01-CONTEXT.md
@.planning/phases/01-research-validation/01-RESEARCH.md
@tools/nanobanana/nanobanana.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Capture video generation flow with Chrome DevTools</name>
  <files>.planning/research/video-generation-findings.md</files>
  <action>
Use Chrome DevTools MCP to capture the complete video generation lifecycle:

1. **Setup capture environment:**
   - Navigate to https://gemini.google.com (user must be logged in with AI Pro)
   - Open Network tab with "Preserve log" enabled
   - Clear existing network entries

2. **Trigger video generation:**
   - Enter prompt: "Generate a 4-second video of ocean waves at sunset"
   - Immediately start capturing ALL network requests

3. **Capture during generation (wait up to 3-5 minutes):**
   - Watch for the trigger request (likely POST to BardChatUi endpoint)
   - Look for ANY subsequent polling requests (interval patterns like every 10s)
   - Look for status check endpoints
   - Note: Video generation can take 2-5 minutes

4. **Capture at completion:**
   - When video appears in UI, capture the retrieval request
   - Document the video URL format
   - Check if URL requires auth headers or works publicly

5. **Document in findings file:**
   - Trigger endpoint URL and method
   - Request headers (especially any model-specific headers like x-goog-ext-*)
   - Request body format (what parameters are sent)
   - Response format (job ID? conversation reference?)
   - Polling endpoint (if exists) and response format
   - Video retrieval URL pattern
   - Auth requirements for video download

**What to look for:**
- Model header similar to image gen: `x-goog-ext-525001261-jspb`
- Operation/job ID in response
- Polling requests at regular intervals
- Video URLs (likely googleusercontent.com domain)

**If video generation fails or times out:**
- Document what was captured
- Note the blocking point
- Try a simpler prompt: "Generate a video of a bouncing ball"
  </action>
  <verify>
`.planning/research/video-generation-findings.md` exists with:
- At least one documented endpoint
- Request/response format notes
- Either video URL pattern OR documented blocker
  </verify>
  <done>Video generation network flow is captured and documented with specific endpoints, headers, and response formats</done>
</task>

<task type="auto">
  <name>Task 2: Replicate flow and download video to Desktop</name>
  <files>tools/nanobanana/video_research.py</files>
  <action>
Create a research script that replicates the captured network flow:

1. **Use existing patterns from nanobanana.py:**
   - Cookie loading from `~/.nanobanana/cookies.json`
   - GeminiClient for auth token acquisition
   - httpx for async requests

2. **Implement discovered endpoints:**
   - Build request body using captured format
   - Include correct model headers (from Task 1 findings)
   - Handle the response to extract job ID or reference

3. **Implement polling (if discovered in Task 1):**
   - Poll status endpoint at discovered interval
   - Parse status response for completion signal
   - Extract video URL when ready

4. **Download video to Desktop:**
   - Fetch video from discovered URL
   - Save to `~/Desktop/research_video.mp4`
   - Handle auth if required (cookies or tokens)

**Script structure:**
```python
#!/usr/bin/env python3
"""Video generation research script for nanobanana."""
import asyncio
import httpx
from pathlib import Path
# ... (follow patterns from nanobanana.py)

# Discovered endpoints from Task 1
TRIGGER_ENDPOINT = "..."  # From findings
POLL_ENDPOINT = "..."     # From findings (if exists)
VIDEO_MODEL_HEADER = {...}  # From findings

async def trigger_video(prompt: str) -> dict:
    """Trigger video generation, return job reference."""
    # Implementation based on findings
    pass

async def poll_status(job_ref: str) -> dict:
    """Poll for video completion status."""
    # Implementation based on findings (if polling exists)
    pass

async def download_video(video_url: str, output_path: Path) -> bool:
    """Download completed video."""
    pass

async def main():
    prompt = "Generate a 4-second video of ocean waves"
    print(f"Triggering video generation: {prompt}")

    job = await trigger_video(prompt)
    print(f"Job reference: {job}")

    # Poll for completion (if applicable)
    # ...

    # Download to Desktop
    output = Path.home() / "Desktop" / "research_video.mp4"
    success = await download_video(video_url, output)

    if success:
        print(f"SUCCESS: Video saved to {output}")
    else:
        print("FAILED: Could not download video")

if __name__ == "__main__":
    asyncio.run(main())
```

**If Task 1 revealed blockers:**
- Document what was attempted in the script
- Add comments explaining the blocking point
- Script should still be runnable (even if it fails with documented reason)
  </action>
  <verify>
Run: `cd /Users/pete/Projects/mr-tools/tools/nanobanana && python video_research.py`
Either:
- Video file exists at `~/Desktop/research_video.mp4` (SUCCESS)
- Script runs and prints documented failure reason (BLOCKER)
  </verify>
  <done>Research script exists and has been executed, with video on Desktop OR clear failure documentation</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Video generation research - either:
- A video file on Desktop (proof of concept works)
- Documented blockers explaining why feature should be dropped
  </what-built>
  <how-to-verify>
1. Check if `~/Desktop/research_video.mp4` exists
2. If yes: Play the video to confirm it's valid
3. If no: Review `.planning/research/video-generation-findings.md` for blockers

**Success criteria:** Video file on Desktop that plays correctly
**Failure criteria:** No video file, but clear documentation of why
  </how-to-verify>
  <resume-signal>
Respond with one of:
- "video works" - Video on Desktop, proceed to Phase 2
- "drop feature" - Confirmed blockers, cancel remaining phases
- Describe issues if something unexpected happened
  </resume-signal>
</task>

</tasks>

<verification>
Phase verification (automated checks):
- `.planning/research/video-generation-findings.md` exists and has content
- `tools/nanobanana/video_research.py` exists and is valid Python
- Either `~/Desktop/research_video.mp4` exists OR findings document blockers

Phase verification (human check at checkpoint):
- Video plays correctly (if exists)
- Blockers are clear and justified (if no video)
</verification>

<success_criteria>
Phase 1 is complete when ONE of these is true:

**Success path:**
- Video file exists at `~/Desktop/research_video.mp4`
- Video plays and shows expected content
- User confirms "video works"
- Proceed to Phase 2: Core Video Generation

**Drop path:**
- No video file on Desktop
- Documented blockers in findings file explain why
- User confirms "drop feature"
- Cancel remaining video phases (2, 3, 4, 5)
</success_criteria>

<output>
After completion, create `.planning/phases/01-research-validation/01-01-SUMMARY.md`

Summary should include:
- Outcome: success or drop
- Key findings (endpoints, formats, auth requirements)
- If success: What worked, what Phase 2 needs to implement
- If drop: What blocked it, why fallback isn't viable
</output>
